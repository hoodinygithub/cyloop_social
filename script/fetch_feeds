#!/usr/bin/env ruby

require 'open-uri'
require 'fileutils'

OUTPUT_LOCATION = "/shared/feeds"
URL_MAPS = [
  # Cyloop Social
  {:url => "http://cm.cyloop.com/feeds/msnbr/msnbr_cysocial_home_featured.xml", :output => "msnbr_url_featured_cysocial.xml"},
  {:url => "http://cm.cyloop.com/feeds/msnmx/msnmx_cysocial_home_featured.xml", :output => "msnmx_url_featured_cysocial.xml"},
  {:url => "http://cm.cyloop.com/feeds/msnlatino/msnlatino_cysocial_home_featured.xml", :output => "msnlatino_url_featured_cysocial.xml"},
  {:url => "http://cm.cyloop.com/feeds/msnlatam/msnlatam_cysocial_home_featured.xml", :output => "msnlatam_url_featured_cysocial.xml"},
  {:url => "http://cm.cyloop.com/feeds/msnlatam/msnlatam_cysocial_home_featured.xml", :output => "msnar_url_featured_cysocial.xml"},
  {:url => "http://cm.cyloop.com/feeds/msncanada/msncaen_cysocial_home_featured.xml", :output => "msncaen_url_featured_cysocial.xml"},
  {:url => "http://cm.cyloop.com/feeds/msncanada/msncafr_cysocial_home_featured.xml", :output => "msncafr_url_featured_cysocial.xml"},
  {:url => "http://cm.cyloop.com/feeds/drupal/cyloop_cysocial_home_featured_en.xml", :output => "cyloop_url_featured_cysocial.xml"},
  {:url => "http://cm.cyloop.com/feeds/drupal/cyloop_cysocial_home_featured_es.xml", :output => "cyloopes_url_featured_cysocial.xml"},
  {:url => "http://cm.cyloop.com/feeds/tvn/tvn_cysocial_home_featured.xml", :output => "tvn_url_featured_cysocial.xml"},
  
  # Latino - News and Promo
  {:url => "http://musica.latino.msn.com/rss_Musica.aspx", :output => "msnlatino_url_news_cysocial.xml"},
  {:url => "http://cm.cyloop.com/feeds/msnlatino/msnlatino_home_promo.xml", :output => "msnlatino_url_promo_cysocial.xml"}
]

timestamp = Time.now.strftime("%Y%m%d%I%M%p")

FileUtils.mkdir_p("#{OUTPUT_LOCATION}/#{timestamp}")

def log(msg)
  File.open("#{OUTPUT_LOCATION}/fetch_log", "a") do |log|
    log.puts "#{Time.now} #{msg}"
  end
end

URL_MAPS.each do |item|
  begin
    log "Fetching #{item[:url]}"
    xml = open(item[:url])
    log "Got response: #{xml.size} bytes"
    if xml.size > 0
      File.open("#{OUTPUT_LOCATION}/#{timestamp}/#{item[:output]}", "w") do |f|
        f.puts xml.read
      end
      log "Wrote #{OUTPUT_LOCATION}/#{timestamp}/#{item[:output]}\n"
    end
  rescue Exception => e
    log "Error fetching #{item.inspect}"
    log e.inspect
    log "\n"
    next
  end
end

valid_fetch = true
URL_MAPS.each do |item|
  if File.size("#{OUTPUT_LOCATION}/#{timestamp}/#{item[:output]}") == 0
    valid_fetch = false
    log "Didn't write output due to #{item.inspect}"
    log "File size of #{OUTPUT_LOCATION}/#{timestamp}/#{item[:output]} was 0\n"
  end
end

if valid_fetch
  system "ln -nsf #{OUTPUT_LOCATION}/#{timestamp} #{OUTPUT_LOCATION}/current"
  log "Finished #{timestamp} fetch"
  log "\n\n"
else
  log "Fetch invalid! valid_fetch false\n\n"
end

# Clean old releases (keep only the last 5)
feeds = `ls -x #{OUTPUT_LOCATION}`
feeds = feeds.split(/\t|\n/).compact.delete_if{|a| a.to_s.strip.empty? }
directories = (feeds - feeds.last(5) - [timestamp]).map { |feed| File.join(OUTPUT_LOCATION, feed.strip) }.join(" ")

system "rm -rf #{directories}"
